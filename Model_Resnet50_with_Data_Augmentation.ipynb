{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "This involves the installation of required libraries and importing them. The colab version also includes mounting the drive and passing the paths to where the files have been stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Google-Colab Version ###\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils import data\n",
    "import time\n",
    "import sklearn\n",
    "import copy\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code snippet to check if any unused variable still occupies GPU Memory \n",
    "\n",
    "### RUN JUST FOR THE COLAB VERSION ###\n",
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size)) \n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)\n",
    "\n",
    "dump_tensors()\n",
    "torch.cuda.empty_cache()\n",
    "import gc \n",
    "model = None\n",
    "learn = None\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN FOR THE JUPYTER VERSION ###\n",
    "\n",
    "## Directories\n",
    "user = getpass.getuser()\n",
    "if user == 'scgst':\n",
    "    dir_home = \"C:\\\\Users\\\\scgst\\\\Documents\\\\Git\\\\COMP5329\\\\Assignment_2\\\\Code\\\\\"\n",
    "elif user == 'mgup6878':\n",
    "    dir_home = \"C:\\\\Users\\\\mgup6878\\\\Desktop\\\\Deep Learning\\\\COMP5329 Assignment 2-20200513T155933Z-001\\\\COMP5329 Assignment 2\\\\Code\\\\\"\n",
    "elif user == 'root':\n",
    "    dir_home = '/content/drive/My Drive/COMP5329 Assignment 2-20200513T155933Z-001.zip (Unzipped Files)/COMP5329 Assignment 2/Code/'\n",
    "\n",
    "dir_input = os.path.join(dir_home, 'Input')\n",
    "dir_output = os.path.join(dir_home, 'Output')\n",
    "\n",
    "dir_data = os.path.join(dir_input, 'data')\n",
    "if user == 'root':\n",
    "    dir_data = os.path.join(dir_input, 'Data2')\n",
    "\n",
    "train_csv = os.path.join(dir_input,'train.csv')\n",
    "test_csv = os.path.join(dir_input,'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed = 27):\n",
    "    \n",
    "    \"\"\"https://pytorch.org/docs/stable/notes/randomness.html\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_all(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 50 # 200 if google colab #30\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "USE_BERT = False\n",
    "USE_OVER_SAMPLING = True\n",
    "\n",
    "TRAIN_TEXT = False\n",
    "\n",
    "# GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in train and test tables\n",
    "with open(train_csv) as file:\n",
    "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "    train_df_full = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "    \n",
    "print(train_df_full.head())\n",
    "print(train_df_full.shape)\n",
    "print(\"\")\n",
    "\n",
    "with open(test_csv) as file:\n",
    "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
    "    test_df = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
    "    \n",
    "print(test_df.head())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "The no. of labels are 18  - [1,2,3,4,5,6,7,8,9,10,11,13,14,15,16,17,18,19]\n",
    "The labels present in given train_data is in the form of space separated strings. These are split into lists and then later one-hot encoded to convert them to format acceptable by the model. The functions below generate *get_encoding(), encode_target(), revert_encoding()* . Their functions are explained in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding(labels):\n",
    "    labels = [[int(n) for n in el ]for el in [w.split(' ') for w in labels.tolist()]]\n",
    "    \n",
    "    # Get \n",
    "    flat_list = []\n",
    "    for sublist in labels:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "            \n",
    "    unique_labels = sorted(list(set(flat_list)))\n",
    "    n_classes = len(unique_labels)\n",
    "    \n",
    "    label_dict = {l:i for i,l in enumerate(unique_labels)}\n",
    "    label_dict_revert = {i:l for i,l in enumerate(unique_labels)}\n",
    "    \n",
    "    return(n_classes, label_dict, label_dict_revert)\n",
    "\n",
    "def encode_target(labels, label_dict, n_classes):\n",
    "    labels = [[int(n) for n in el ]for el in [w.split(' ') for w in labels.tolist()]]\n",
    "    \n",
    "    labels_expanded = []\n",
    "    for el in labels:\n",
    "        label_arr = [0] * n_classes\n",
    "        for l in el:\n",
    "            d = label_dict[l]\n",
    "            label_arr[d] = 1\n",
    "        labels_expanded.append(label_arr)\n",
    "        \n",
    "    return labels_expanded\n",
    "# labels_expanded = encode_target(labels, label_dict, n_classes)\n",
    "\n",
    "def revert_encoding(labels_expanded, label_dict_revert):\n",
    "    full_map = []\n",
    "    for el in labels_expanded:\n",
    "        c = 0\n",
    "        label_revert = []\n",
    "        for l in el:\n",
    "            if (l == 1):\n",
    "                d = label_dict_revert[c]\n",
    "                d = str(d)\n",
    "                label_revert.append(d)\n",
    "            c += 1\n",
    "        s = \" \".join(label_revert)\n",
    "        full_map.append(s)\n",
    "    \n",
    "    return full_map\n",
    "\n",
    "# encode_reverted = revert_encoding(labels_expanded, label_dict_revert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df_full['Labels']\n",
    "n_classes, label_dict, label_dict_revert = get_encoding(labels)\n",
    "print(n_classes)\n",
    "print(label_dict)\n",
    "print(label_dict_revert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "labels_expanded = encode_target(labels, label_dict, n_classes)\n",
    "\n",
    "# Add encoded labels to train table\n",
    "train_df_full['Expanded_Labels'] = labels_expanded\n",
    "train_df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embeddings\n",
    "The following code aims to get the sentence embeddings for each image caption for both train and test datasets. For this we simply use the pre-trained BERT model 'bert-base-uncased'. The model is then ran in the *eval()* mode to get the embeddings. The *get_bert_embeddings()* contains the implementation to preprocess the data, get the word embeddings for each caption from the second to the last hidden layers and averaging them to get one sentence embedding. As the dataset is quite large, to avoid memory issues, we are splitting the dataset to get embeddings batchwise, then combining them to make a single tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "text_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(X_captions, MAX_LEN, tokenizer, model):\n",
    "    tokenized_list = []\n",
    "    ids_list = []\n",
    "    seg_id_list = []\n",
    "    for sent in X_captions:\n",
    "\n",
    "        tokenize = tokenizer.tokenize('[CLS] ' + sent + ' [SEP]')\n",
    "        \n",
    "        if len(tokenize) > MAX_LEN : tokenize  = tokenize[:MAX_LEN]\n",
    "            \n",
    "        ids = tokenizer.convert_tokens_to_ids(tokenize)\n",
    "            \n",
    "        ids = torch.tensor(ids + [0] * (MAX_LEN - len(ids)))\n",
    "\n",
    "        segments_ids = torch.tensor([1]* MAX_LEN)\n",
    "        \n",
    "        seg_id_list.append(segments_ids)\n",
    "        tokenized_list.append(tokenize)\n",
    "        ids_list.append(ids)\n",
    "\n",
    "    \n",
    "    tokens_tensor = torch.stack(ids_list)\n",
    "    segments_tensors = torch.stack(seg_id_list)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor.to(device), segments_tensors.to(device))\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    \n",
    "    \n",
    "    token_vecs = encoded_layers[11]\n",
    "    # Calculate the average of all 59 token vectors.\n",
    "    sentence_embeddings = torch.mean(token_vecs, dim=1)\n",
    "    \n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to concat list of tensors to one tensor\n",
    "#### Code cell 3\n",
    "def all_dataset_embeddings(X_captions, BATCH_SIZE, MAX_LEN, tokenizer, model,mode = 'training'):\n",
    "    n_batches = math.ceil(len(X_captions)/BATCH_SIZE)\n",
    "    #sent_emb_list = [get_bert_embeddings(X_captions[i * BATCH_SIZE:(i+1)*BATCH_SIZE], MAX_LEN, tokenizer,model) for i in range(0, n_batches)]\n",
    "    sent_emb_list = []\n",
    "    for i in range(0, n_batches):\n",
    "        sent_emb = get_bert_embeddings(X_captions[i * BATCH_SIZE:(i+1)*BATCH_SIZE], MAX_LEN, tokenizer,model)     \n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Text Batch Process for {} set: {}/{} | Time: {}\".format(\n",
    "                mode,\n",
    "                str(i),\n",
    "                str(n_batches),\n",
    "                datetime.now()\n",
    "            ))\n",
    "        sent_emb_list.append(sent_emb)\n",
    "    return torch.cat(sent_emb_list, dim = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the sentence embeddings\n",
    "After saving the embeddings once, we no longer would want to run the code again to get same results. To avoid the hassle, we will load the saved embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "TEXT_BATCH_SIZE = 1000\n",
    "MAX_LEN = 59\n",
    "# Load pre-trained BERT model\n",
    "text_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "if USE_BERT:\n",
    "    if TRAIN_TEXT:\n",
    "        train_emb_list= all_dataset_embeddings(\n",
    "            train_df_full.iloc[:, 2], TEXT_BATCH_SIZE , MAX_LEN, tokenizer, text_model, 'training'\n",
    "        )\n",
    "        test_emb_list =  all_dataset_embeddings(\n",
    "            test_df.iloc[:, 1], TEXT_BATCH_SIZE, MAX_LEN, tokenizer, text_model, 'testing'\n",
    "        )\n",
    "        \n",
    "        ## Saving the embeddings for later use\n",
    "        torch.save(train_emb_list, os.path.join(dir_output, 'train_emb.pt'))\n",
    "        torch.save(test_emb_list, os.path.join(dir_output, 'test_emb.pt'))\n",
    "        \n",
    "    else:\n",
    "        train_emb_list = torch.load(os.path.join(dir_output, 'train_emb.pt'))\n",
    "        test_emb_list = torch.load(os.path.join(dir_output, 'test_emb.pt'))\n",
    "       \n",
    "    TEXT_LENGTH = train_emb_list.shape[1]\n",
    "    print(train_emb_list.shape, test_emb_list.shape)\n",
    "    \n",
    "else:\n",
    "    TEXT_LENGTH = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Exploratory\n",
    "\n",
    "Exploratory Data Analysis results reveal that the dataset is highly imbalanced due to bias towards label '1'. Based on manual analysis, the dataset seems to be a computer-vision challenge to find identify multiple entities in an image. For example -- humans, cats, trains, bikes etc. Some images have multi-labels which some have just have pure labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution before sample\n",
    "print(np.sum(labels_expanded, axis = 0))\n",
    "\n",
    "# Classes are unbalanced\n",
    "# Label one has more chances to be classfield \n",
    "# Up sampling cases with data augmentation to potentially resolve the unbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning weights to each class such that dominant class is weighed less and less dominant are weighted more\n",
    "## These weights can be used to manage the data imbalance.\n",
    "## This technique wasn't found to be much useful for our dataset. Hence Data Augmentation was used for our dataset.\n",
    "tot_list = list(np.sum(labels_expanded, axis = 0))\n",
    "max_sample = max(tot_list)\n",
    "weights_per_label = [max_sample/n for n in tot_list]\n",
    "print(max_sample)\n",
    "print(weights_per_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_OVER_SAMPLING:\n",
    "    # Index for cases have label one and do not have label one\n",
    "    NO_LABEL_ONE_INDEX = []\n",
    "    LABEL_ONE_INDEX = []\n",
    "    for i in range(len(labels_expanded)):\n",
    "        el = labels_expanded[i]\n",
    "        if el[0] == 0:\n",
    "            NO_LABEL_ONE_INDEX.append(i)\n",
    "        else:\n",
    "            LABEL_ONE_INDEX.append(i)\n",
    "\n",
    "    # Sampling cases not having label one\n",
    "    TIMES_TO_EXTRACT_UNBALANCE_CALSS = 10\n",
    "    SAMPLE_SIZE = 5000\n",
    "    SAMPLE_NON_LABEL_ONE_INDEX = []\n",
    "    for i in range(TIMES_TO_EXTRACT_UNBALANCE_CALSS):\n",
    "        SAMPLE_NON_LABEL_ONE_INDEX.append(np.random.choice(NO_LABEL_ONE_INDEX, SAMPLE_SIZE))\n",
    "    SAMPLE_NON_LABEL_ONE_INDEX = np.concatenate(SAMPLE_NON_LABEL_ONE_INDEX)\n",
    "    FULL_DATA_INDEX = np.concatenate([LABEL_ONE_INDEX, NO_LABEL_ONE_INDEX, SAMPLE_NON_LABEL_ONE_INDEX])\n",
    "    # Class distribution before sample\n",
    "    CLASS_AFTER_SAMPLE = []\n",
    "    for i in FULL_DATA_INDEX:\n",
    "        CLASS_AFTER_SAMPLE.append(labels_expanded[i])\n",
    "    print(np.sum(CLASS_AFTER_SAMPLE, axis = 0))\n",
    "    train_df_full_new = pd.DataFrame(\n",
    "        train_df_full, \n",
    "        columns = ['ImageID' , 'Labels', 'Caption', 'Expanded_Labels'],\n",
    "        index = FULL_DATA_INDEX\n",
    "    ) \n",
    "    \n",
    "    train_df_full = train_df_full_new.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partition\n",
    "\n",
    "The  data was split into train and validation sets in the ratio 70:30. Hence, the no. of examples in train set were 20,997 and that in validation set 8,999. The trained BERT embeddings were split in the same ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_INDEX = range(0, len(train_df_full))\n",
    "TRAIN_INDEX, VAL_INDEX = train_test_split(ALL_INDEX, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(\n",
    "    train_df_full, \n",
    "    columns = ['ImageID' , 'Labels', 'Caption', 'Expanded_Labels'],\n",
    "    index = TRAIN_INDEX\n",
    ") \n",
    "train_df = train_df.reset_index(drop = True)\n",
    "\n",
    "val_df = pd.DataFrame(\n",
    "    train_df_full, \n",
    "    columns = ['ImageID' , 'Labels', 'Caption', 'Expanded_Labels'],\n",
    "    index = VAL_INDEX\n",
    ") \n",
    "val_df = val_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_BERT:\n",
    "    train_emb = train_emb_list[TRAIN_INDEX]\n",
    "    val_emb = train_emb_list[VAL_INDEX]\n",
    "    test_emb = test_emb_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "\n",
    "The following *ImageData* class aims to build a custom dataset in a format that can be used by the dataloader. It takes the dataframe as an input which can be the train/validation/test sets containing the ImageId column containing image file names and the one-hot-encoded labels(only for the train/validation sets), the path to the folder containing the images, and a parameter 'test' which if true indicates it is a test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "class ImageData(data.Dataset):\n",
    "    def __init__(self, df, dirpath, transform, test = False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.dirpath = dirpath\n",
    "        self.transform = transform\n",
    "        \n",
    "        # image data \n",
    "        self.image_arr = np.asarray(str(self.dirpath) + '/' + self.df.iloc[:, 0])          \n",
    "        \n",
    "        # labels data\n",
    "        if not self.test:\n",
    "             self.label_df = self.df.iloc[:, 3]\n",
    "        \n",
    "        # Calculate length of df\n",
    "        self.data_len = len(self.df.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_arr[idx]\n",
    "        img = Image.open(image_name)\n",
    "        img_tensor = self.transform(img)\n",
    "        if not self.test:\n",
    "            image_labels = self.label_df[idx]                \n",
    "            image_label = torch.tensor(image_labels, dtype= torch.float32)\n",
    "            return (img_tensor, image_label.squeeze())\n",
    "        \n",
    "        return (img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image transformation \n",
    "### The following code mentions the data augmentation transformations applied to images in each of the datasets.\n",
    "### Each dataset is the loaded onto respective dataloaders to be used while training\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p = 0.5),\n",
    "#         transforms.RandomVerticalFlip(p = 0.5),\n",
    "#         transforms.RandomRotation(degrees = [-45, 45]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.RandomResizedCrop(224), \n",
    "        transforms.RandomHorizontalFlip(p = 0.5),\n",
    "#         transforms.RandomVerticalFlip(p = 0.5),\n",
    "#         transforms.RandomRotation(degrees = [-45, 45]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Loading data\n",
    "train_dataset = ImageData(train_df, dir_data, data_transforms['train'])\n",
    "train_loader = data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "features_train, labels_train = next(iter(train_loader))\n",
    "\n",
    "val_dataset = ImageData(val_df, dir_data, data_transforms['val'])\n",
    "val_loader = data.DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "features_val, labels_val = next(iter(val_loader))\n",
    "\n",
    "# train_full_dataset = ImageData(train_df_full, dir_data, data_transforms['train'])\n",
    "# train_full_loader = data.DataLoader(\n",
    "#     dataset = train_full_dataset,\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     shuffle = False\n",
    "# )\n",
    "# features_train_full, labels_train_full = next(iter(train_full_loader))\n",
    "\n",
    "test_dataset = ImageData(test_df, dir_data, data_transforms['test'], test = True)\n",
    "test_loader = data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "features_test = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Data Length: {len(train_df)}\\nMini Batch Size: {BATCH_SIZE}\\nBatch Numbers: {len(train_loader)}\\nTrain Features: {features_train.shape}\\nTrain Labels: {labels_train.shape}\")\n",
    "print()\n",
    "print(f\"Validation Data Length: {len(val_df)}\\nMini Batch Size: {BATCH_SIZE}\\nBatch Numbers: {len(val_loader)}\\nValidation Features: {features_val.shape}\\nValidation Labels: {labels_val.shape}\")\n",
    "print()\n",
    "# print(f\"Full Train Data Length: {len(train_df_full)}\\nMini Batch Size: {BATCH_SIZE}\\nBatch Numbers: {len(train_full_loader)}\\nFull Train Features: {features_train_full.shape}\\nFull Train Labels: {labels_train_full.shape}\")\n",
    "# print()\n",
    "print(f\"Test Data Length: {len(test_df)}\\nMini Batch Size: {BATCH_SIZE}\\nBatch Numbers: {len(test_loader)}\\nTest Features: {features_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to empty the GPU cache ; Alternatively, you may restart the session and clear all the outputs\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model using torchvision.models as models library\n",
    "model = models.resnet50(pretrained = True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')\n",
    "print()\n",
    "\n",
    "fc_input = model.fc.in_features\n",
    "print('Number of Outputs from resent50 features: ' + str(fc_input))\n",
    "print()\n",
    "\n",
    "num_labels = n_classes #PUT IN THE NUMBER OF LABELS IN YOUR DATA\n",
    "fc = nn.Sequential(\n",
    "    nn.Linear(fc_input + 0, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, num_labels),\n",
    "    nn.Sigmoid() # LogSoftmax(dim = 1) # \n",
    ")\n",
    "# Replace default classifier with new classifier\n",
    "model.fc = fc\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')\n",
    "\n",
    "# Move model to the device specified above\n",
    "model.to(device)\n",
    "\n",
    "# Set the error function using torch.nn as nn library\n",
    "criterion = nn.BCELoss() #BCEWithLogitsLoss\n",
    "\n",
    "# Set the optimizer function using torch.optim as optim library\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_per_label = torch.FloatTensor(weights_per_label).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "running_train_loss = []\n",
    "running_val_loss = []\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    # Training the model\n",
    "    model.train()\n",
    "    mini_batch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Print the progress of our training\n",
    "        if (mini_batch_counter % 50) == 0:\n",
    "            print(\"Epoch: {}/{} | Phase: 'Train' | Batch: {}/{} | Time: {}\".format(\n",
    "              epoch + 1,\n",
    "              NUM_EPOCHS, \n",
    "              mini_batch_counter + 1,\n",
    "              len(train_loader),\n",
    "              datetime.now()\n",
    "            ))\n",
    "           \n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Clear optimizers\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model.forward(inputs)\n",
    "        # Loss\n",
    "        loss = criterion(output, labels)\n",
    "        # Calculate gradients (backpropogation)\n",
    "        loss.backward()\n",
    "        # Adjust parameters based on gradients\n",
    "        optimizer.step()\n",
    "        # Add the loss to the training set's running loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        mini_batch_counter += 1\n",
    "    \n",
    "    # Get the average loss for the entire epoch\n",
    "    train_loss = train_loss / len(train_loader.dataset)   \n",
    "    running_train_loss.append(train_loss)\n",
    "    elapsed_train_time = time.time() - start_time\n",
    "    \n",
    "    print('Epoch: {} / {} \\tTraining Loss: {:.6f} \\tTrain Time: {:.6f}mins'.format(\n",
    "        epoch + 1, NUM_EPOCHS, train_loss, elapsed_train_time / 60\n",
    "    ))\n",
    "\n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "    mini_batch_counter = 0\n",
    "    # Tell torch not to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # Print the progress of our training\n",
    "            if (mini_batch_counter % 50) == 0:\n",
    "                print(\"Epoch: {}/{} | Phase: 'Test' | Batch: {}/{} | Time: {}\".format(\n",
    "                  epoch + 1,\n",
    "                  NUM_EPOCHS, \n",
    "                  mini_batch_counter + 1,\n",
    "                  len(val_loader),\n",
    "                  datetime.now()\n",
    "                ))\n",
    "               \n",
    "            # Move to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            output = model.forward(inputs)\n",
    "            # Calculate Loss\n",
    "            valloss = criterion(output, labels)\n",
    "            # Add loss to the validation set's running loss\n",
    "            val_loss += valloss.item()*inputs.size(0)\n",
    "\n",
    "            mini_batch_counter += 1\n",
    "            \n",
    "    # Get the average loss for the entire epoch\n",
    "    valid_loss = val_loss/len(val_loader.dataset)\n",
    "    running_val_loss.append(valid_loss)\n",
    "    elapsed_test_time = time.time() - start_time - elapsed_train_time\n",
    "    \n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # Print out the information\n",
    "    print('Epoch: {} / {} \\tValidation Loss: {:.6f} \\tValidation Time: {:.6f}mins'.format(\n",
    "        epoch + 1, NUM_EPOCHS, valid_loss, elapsed_test_time/60\n",
    "    ))\n",
    "    \n",
    "    # plot the cost\n",
    "    plt.plot(running_val_loss)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()\n",
    "\n",
    "print('Best Epoch is ' + str(best_epoch))\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss v.s. Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost\n",
    "plt.plot(running_train_loss)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost\n",
    "plt.plot(running_val_loss)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Scoring on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Get output\n",
    "start_time = time.time()\n",
    "whole_val_outputs = np.zeros((len(val_dataset), n_classes))\n",
    "whole_val_labels = np.zeros((len(val_dataset), n_classes))\n",
    "\n",
    "mini_batch_counter = 0\n",
    "for val_batch_input, val_batch_labels in val_loader:\n",
    "    if ((mini_batch_counter) % 50 == 0):\n",
    "        print(str(mini_batch_counter + 1) + '/' + str(len(val_loader)))\n",
    "\n",
    "    # Forward pass\n",
    "    val_batch_output = model.forward(val_batch_input.to(device)).detach().cpu().numpy()\n",
    "    val_batch_labels = val_batch_labels.detach().cpu().numpy()\n",
    "    \n",
    "    whole_val_outputs[mini_batch_counter * BATCH_SIZE:(mini_batch_counter + 1) * BATCH_SIZE, :] = val_batch_output\n",
    "    whole_val_labels[mini_batch_counter * BATCH_SIZE:(mini_batch_counter + 1) * BATCH_SIZE, :] = val_batch_labels\n",
    "    mini_batch_counter += 1\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_val_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(whole_val_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(whole_val_outputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prediction on Validation\n",
    "whole_val_predictions = np.round(whole_val_outputs)\n",
    "print(sklearn.metrics.f1_score(\n",
    "    y_true = whole_val_labels, y_pred = whole_val_predictions, average = 'weighted'\n",
    "))\n",
    "\n",
    "# PERCENTILE = 99.7\n",
    "# whole_val_predictions = np.zeros(whole_val_outputs.shape)\n",
    "# for i in range(len(whole_val_outputs)):\n",
    "#     whole_val_predictions[i, whole_val_outputs[i] > np.percentile(whole_val_outputs[i], PERCENTILE)] = 1\n",
    "\n",
    "# # Calculate F1 Score on validation set\n",
    "# print(sklearn.metrics.f1_score(y_true = whole_val_labels, y_pred = whole_val_predictions, average = 'weighted'))\n",
    "# # # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "# # print(sklearn.metrics.f1_score(y_true = whole_val_labels, y_pred = whole_val_predictions, average = 'sample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_val_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Prediction\n",
    "# Get output\n",
    "start_time = time.time()\n",
    "whole_test_outputs = np.zeros((len(test_dataset), n_classes))\n",
    "whole_test_outputs = np.zeros((len(test_dataset), n_classes))\n",
    "mini_batch_counter = 0\n",
    "for test_batch_input in test_loader:\n",
    "    if ((mini_batch_counter) % 50 == 0):\n",
    "        print(str(mini_batch_counter + 1) + '/' + str(len(test_loader)))     \n",
    "\n",
    "    # Forward\n",
    "    test_batch_output = model.forward(test_batch_input.to(device)).detach().cpu().numpy()\n",
    "    \n",
    "    whole_test_outputs[mini_batch_counter * BATCH_SIZE:(mini_batch_counter + 1) * BATCH_SIZE, :] = test_batch_output\n",
    "    mini_batch_counter += 1\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prediction on Validation\n",
    "whole_test_predictions = np.round(whole_test_outputs)\n",
    "\n",
    "# # Get Prediction on Test\n",
    "# PERCENTILE = 99.7\n",
    "# whole_test_predictions = np.zeros(whole_test_outputs.shape)\n",
    "# for i in range(len(whole_test_predictions)):\n",
    "#     whole_test_predictions[i, whole_test_outputs[i] > np.percentile(whole_test_outputs[i], PERCENTILE)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = revert_encoding(whole_test_predictions, label_dict_revert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(submission).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['Labels'] = submission\n",
    "test_df = test_df.drop(columns = 'Caption')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(dir_output, 'Submission_Model_V12_Resnet_with_Data_Augmentation.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "PATH = os.path.join(dir_output, 'Model_V12_Resnet_with_Data_Augmentation.pth')\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
